<!DOCTYPE html>
<html lang="" xml:lang="">
  <head>
    <title>GNR</title>
    <meta charset="utf-8" />
    <meta name="author" content="Seiro Ito" />
    <script src="libs/header-attrs-2.25/header-attrs.js"></script>
    <link href="libs/remark-css-0.0.1/default.css" rel="stylesheet" />
    <link href="libs/remark-css-0.0.1/default-fonts.css" rel="stylesheet" />
    <link href="libs/panelset-0.2.6/panelset.css" rel="stylesheet" />
    <script src="libs/panelset-0.2.6/panelset.js"></script>
    <link rel="stylesheet" href="xaringan-themer.css" type="text/css" />
  </head>
  <body>
    <textarea id="source">
class: center, middle, inverse, title-slide

.title[
# GNR
]
.subtitle[
## A. Gandhi, S. Navarro, and D. A. Rivers. “On the identification of gross output production functions”. <em>Journal of Political Economy</em>, 128.8 (2020).
]
.author[
### Seiro Ito
]
.date[
### 2024年02月06日 15:11
]

---

class: inverse


&lt;div style = "position:fixed; visibility: hidden"&gt;
`$$\require{color}\definecolor{red}{rgb}{1, 0, 0}$$`
`$$\require{color}\definecolor{green}{rgb}{0, 1, 0}$$`
`$$\require{color}\definecolor{blue}{rgb}{0, 0, 1}$$`
&lt;/div&gt;
&lt;script type="text/x-mathjax-config"&gt;
MathJax.Hub.Config({
  TeX: {
    Macros: {
      red: ["{\\color{red}{#1}}", 1],
      green: ["{\\color{green}{#1}}", 1],
      blue: ["{\\color{blue}{#1}}", 1]
    },
    loader: {load: ['[tex]/color']},
    tex: {packages: {'[+]': ['color']}}
  }
});
&lt;/script&gt;
&lt;style&gt;
.red {color: #FF0000;}
.green {color: #00FF00;}
.blue {color: #0000FF;}
&lt;/style&gt;

&lt;style type="text/css"&gt;
.highlight-last-item &gt; ul &gt; li,
.highlight-last-item &gt; ol &gt; li {
  opacity: 0.5;
}
.highlight-last-item &gt; ul &gt; li:last-of-type,
.highlight-last-item &gt; ol &gt; li:last-of-type {
  opacity: 1;
}
.inverse {
  background-color: #272822;
  color: #d6d6d6;
  text-shadow: 0 0 20px #333;
}
mark.red {
    color:#ff0000;
    background: none;
}
mark.blue {
    color:#0000A0;
    background: none;
}
.my-style {
  font-weight: bold;
  font-style: italic;
  font-size: 1.5em;
  color: red;
}
blockquote {
  border-left: .2px solid #275d38;
  margin: -5px 80px -5px 20px;
  padding-top: -0.5px;
  padding-bottom: -0.5px;
  line-height: 1.35em;
}
&lt;/style&gt;

&lt;script type="text/x-mathjax-config"&gt;
MathJax.Hub.Config({
  TeX: {
    Macros: {
      E: "{\\Large\\varepsilon}",
      bfx: "{\\mathbf{x}}",
      bfX: "{\\mathbf{X}}",
      bfalpha: "{\\boldsymbol{\\alpha}}",
      bfbeta: "{\\boldsymbol{\\beta}}",
      st: "{\\mbox{s.t.}}"
    }
  }
});
&lt;/script&gt;

## Gross output production function parameters are not indentified. 

--

## When using profit maximization FOC in material demand inversion and using lagged inputs as IVs to estimate other parameters.  

--

## Exogeonous material demand variations (say, by input prices which may or maynot be observed) can help identification but weak.

[Gandhi, Navarro, and Rivers (2020)](         https://doi.org/10.1086/707736)


---
class: inverse

### Then, can't we just use a VA production function instead?

--

&gt; the conditions which a value added production function can straightforwardly be derived from a more primitive gross output production function are quite restrictive.  

&lt;p style="margin-bottom:2cm;"&gt;.pull-left[] .pull-right[[De Loecker and Syverson (2021, 5.6.2)](#bib-DeLoeckerSyverson2021)]&lt;/p&gt;

--

Taking out VA from Y=VA(K, L)+M form 

* Gives a .red[biased estimate] when regressing `\(VA\)` on `\(K, L\)`, except  under ([Basu and Fernald, 1997](https://doi.org/10.1086/262073), p.255)  

--

  * Zero markup in output markets, or,  
  * Zero substitution between `\((K, L)\)` and `\(M\)` (Leontief-in-materials).  

--

* Does not admit contribution of `\(M\)` to TFP growth.  

--

  * At odds with a growing recognition on the role of imported intermediate goods on TFP.  

---
class: inverse

### Macro TFP literature uses value-added production functions. 

--

### Macro misallocation, IO, and trade literature use gross output production functions. 

* Imported goods on TFP.  
* Separating demand side heterogeneity (shocks, markups) from TFP.  
* [Ackerberg, Caves, and Frazer (2015)](https://onlinelibrary.wiley.com/doi/abs/10.3982/ECTA13408) considers identification of VA production with material input inversion (conditional on `\(l_{jt}\)`) = gross output production function with Leontief in materials. Not general gross output production functions.

--

### Dev econ uses VA production as household production functions (ag HH model, etc.) with time-invariant shocks `\(\omega_{j}\)`.

* Effectively hid the problem under the rug, using FEs looked fine.  
* HH data often include input/output `\(p\)` and `\(q\)` separately, rendering IV+FE use.  
* Could have estimated VA+LIM or GO production functions with `\(\omega_{jt}\)`.  


---
### Why unidentified?

* Given `\(\omega_{jt-1}, k_{jt}\)`, `\(m_{jt-1}(\omega_{jt-1}, \epsilon_{jt-1})\)` is uncorrelated with `\(m_{jt}(\omega_{jt-1}+\xi_{jt}, \epsilon_{jt})\)`, so cannot be used as an IV.  
* Oversimplifying, but, when `\(f(\bfx_{jt})+h(\bfx_{i, t-1}, d_{t-1})\)` is on RHS, it is hard to separately identify `\(f\)` and `\(h\)` with `\(\bfx_{i,t-1}\)` as IVs. 

* Substitution of `\(\omega_{jt}\)` using material demand (proxy variable) or AR(1) (dynamic panel) suffers.  

---
### What does it mean if we want to estimate wage markdown using financial statement data?
 
--

* It means we must do it with VA or VA+Leontief-in-materials ([Ackerberg, Caves, and Frazer, 2015](https://onlinelibrary.wiley.com/doi/abs/10.3982/ECTA13408); [Rubens, 2023](https://www.aeaweb.org/articles?id=10.1257/aer.20210383)).   

  * [Rubens (2023)](https://www.aeaweb.org/articles?id=10.1257/aer.20210383) derives an estimable markdown formula for a monopsonist.  
  * [Bruno (1978b)](#bib-Bruno1978); [Diewert (1978)](#bib-Diewert1978): Without ex-post shocks `\(\epsilon_{jt}\)`, VA elasticity `\(\simeq \frac{\textrm{VA}}{\textrm{GO}}\)` * gross output elastictiy.  
  * [Gandhi, Navarro, and Rivers (2017)](https://publish.uwo.ca/~drivers2/research/comparing_go_va_full.pdf): With ex-post shocks `\(\epsilon_{jt}\)`, VA elasticity `\(\neq \frac{\textrm{VA}}{\textrm{GO}}\)` * gross output elastictiy, except...  
    * if gross output is LIM and material input enters linearly `\(\min\{\mathcal H(K_{jt}, L_{jt}), aM_{jt}\}\)`, one can estimate VA production function with `\(Y_{jt}=\mathcal H(K_{jt}, L_{jt})e^{\omega_{jt}+\epsilon_{jt}}\)`.  

--

* Other cases: When are materials substitutable with capital and labour? Energy. But not coffee beans for coffee. 

--

* VA or VA+LIM can be good enough in measuring wage markdown ([Hashemi, Kirov, and Traina, 2022](https://www.sciencedirect.com/science/article/pii/S0165176522002257)).  

---
class: middle, center, inverse

# Issue: Transmission/endogeneity problem

---
class: inverse
### Estimate production function parameters under Hicks-neutral unobservable heterogenous productivity `\(\omega_{j}\)`?

`\begin{equation*}
y_{j}=f(K_{j}, L_{j}, \omega_{j})+\epsilon_{j}=f(K_{j}, L_{j})+\omega_{j}+\epsilon_{j}. 
\end{equation*}`

--

### OLS estimates are biased: "Transmission problem".

--

* There remains a separate bias of omitted prices ([De Loecker and Goldberg, 2014](https://doi.org/10.1146/annurev-economics-080113-104741))

--

### Use FE. But what if `\(\omega_{j}=\omega_{jt}\)`? FE does not solve the problem.

--

### Solution: Lagged input decision (lagged input variable) is orthogonal to current shocks. IV.  

* Dynamic panel estimators.  
* Proxy variable methods.  
---
class: inverse
### GNR: 1. Lagged input = IV does not nonparametrically identify parameters.  

--

### GNR: 2. Use of price-taker profit max FOC achieves identification.  

--

### (Price-taker profit max is restrictive.)
---
class: inverse, center, middle

# Negative result: Nonparametric nonidentification

---
class: inverse

### `\(y_{jt}=f(\bfx_{jt})+\omega_{jt}+\epsilon_{jt}\)`

--

### Substitute unobservable productivity `\(\omega_{jt}\)` with `\(h(\bfx_{jt-1},d_{t-1})\)`, real factor price `\(d_{t-1}\)`.

--

### If `\(d_{t}\)` is constant, conditional (on IV, usually `\(\bfx_{jt-1}\)`) expectation of `\(y_{jt}\)` cannot separately identify parameters of `\(f, h\)`.
--

### This also holds for dynamic panel estimators. 

--

### Monte Carlo: Even when `\(d_{t}\)` varies, identification is weak, not usable.
---
class: inverse
Production function

&lt;!--$$`
Y_{jt}=F^{0}(K_{jt}, L_{jt}, M_{jt})e^{\omega_{jt}+\epsilon_{jt}}.
`$$--&gt;

`\begin{aligned}
Y_{jt}
&amp;=F^{0}(K_{jt}, L_{jt}, M_{jt})e^{\omega_{jt}+\epsilon_{jt}},\\
y_{jt}
&amp;=
f^{0}\left(\bfx_{jt}\right)+\omega_{jt}+\epsilon_{jt},\\
&amp;=
f^{0}\left(\bfx_{jt}\right)-f^{0}_{M}\left(\bfx_{jt}\right)-\E[\epsilon_{jt}]+d_{t}+\epsilon_{jt}.
\end{aligned}`

where we used price-taking expected profit maximization FOC

`\begin{equation*}
\max_{M_{jt}}
\;\;\; \E\left[P_{jt}F^{0}(K_{jt}, L_{jt}, M_{jt})e^{\omega_{jt}+\epsilon_{jt}}\right]-\rho_{jt}M_{jt}
\end{equation*}`

`\begin{equation*}
\frac{\partial F^{0}\left(\bfx_{jt}\right)e^{\omega_{jt}}\E[e^{\epsilon_{jt}}]}{\partial M_{jt}}=\frac{\rho_{jt}}{P_{jt}}.
\end{equation*}`

`\begin{equation*}
f^{0}_{M}\left(\bfx_{jt}\right)+\omega_{jt}+\E[\epsilon_{jt}]=\underbrace{\ln\rho_{t}-p_{t}}_{\equiv d_{t}},
\quad 
f^{0}_{M}\left(\bfx_{jt}\right)=\ln\frac{\partial F^{0}\left(\bfx_{jt}\right)}{\partial M_{jt}},
\end{equation*}`
so one can solve for `\(\omega_{jt}\)` ("invert")
`\begin{equation*}
\omega_{jt}
=
-f^{0}_{M}\left(\bfx_{jt}\right)-\E[\epsilon_{jt}]+d_{t}.
\end{equation*}`
---
class: inverse
`\begin{aligned}
\omega_{jt}
&amp;=
\underbrace{-f^{0}_{M}\left(\bfx_{jt}\right)-\E[\epsilon_{jt}]}_{\equiv M^{-1}\left(\bfx_{jt}\right)}+d_{t},\\
y_{jt}
&amp;=
f^{0}\left(\bfx_{jt}\right)+\omega_{jt}+\epsilon_{jt},\\
&amp;=
\underbrace{f^{0}\left(\bfx_{jt}\right)+M^{-1}\left(\bfx_{jt}\right)}_{\equiv \phi_{G}\left(\bfx_{jt}\right)}+d_{t}+\epsilon_{jt}.\quad (\phi_{G}+d_{t}=\phi \ \mathrm{of\ DLW})
\end{aligned}`

Using `\(\phi_{G}\)`
`\begin{aligned}
\omega_{jt}
&amp;=
f^{0}\left(\bfx_{jt}\right)+M^{-1}\left(\bfx_{jt}\right)+d_{t}-f^{0}\left(\bfx_{jt}\right),\\
&amp;=
\phi_{G}\left(\bfx_{jt}\right)+d_{t}-f^{0}\left(\bfx_{jt}\right),\\
\omega_{jt-1}
&amp;=
\phi_{G}\left(\bfx_{jt-1}\right)+d_{t-1}-f^{0}\left(\bfx_{jt-1}\right).
\end{aligned}`

First-order Markov ass. gives
`\begin{aligned}
\omega_{jt}
&amp;=
h^{0}\left(\omega_{jt-1}\right)+\xi_{jt}, \quad (h^{0}=g \ \mathrm{of\ DLW})\\
&amp;=
h^{0}\left\{\phi_{G}\left(\bfx_{jt-1}\right)+d_{t-1}-f^{0}\left(\bfx_{jt-1}\right)\right\}+\xi_{jt}.
\end{aligned}`
So, with price-taking profit max FOC and FO Markov, we get
`\begin{equation*}
y_{jt}=f^{0}\left(\bfx_{jt}\right)+h^{0}\left\{\phi_{G}\left(\bfx_{jt-1}\right)+d_{t-1}-f^{0}\left(\bfx_{jt-1}\right)\right\}+\xi_{jt}+\epsilon_{jt}.
\end{equation*}`
---
class: inverse
Theorem 1: Nonidentification of parameters
### If real factor price `\(d_{t}=d\)` for all `\(t\)`,  model+data `\(\rightarrow\)` non unique parameter sets

* Conditional expectation (conditioned on IVs `\(\Gamma_{jt}\)`) of `\(y_{jt}=f^{0}(\bfx_{jt})+h^{0}(z)+\xi_{jt}+\epsilon_{jt}\)` can be expressed as `\(\E\left[f^{0}(\bfx_{jt})\left|\right.\Gamma_{jt}\right]+\E\left[h^{0}(z)\left|\right.\Gamma_{jt}\right]\)`.  
* But, when we define new functions `\(\tilde{f}\neq f^{0}, \tilde{h}\neq h^{0}\)` by mixing a nuisance function at a constant proportion `\(a\)` for any `\(a\in(0, 1)\)` as in the below, we can show (in Theorem 1) that their conditional (on IVs) expectations are same `\(\E\left[f^{0}(\bfx_{jt})\left|\right.\Gamma_{jt}\right]+\E\left[h^{0}(z)\left|\right.\Gamma_{jt}\right]=\E\left[\tilde{f}(\bfx_{jt})\left|\right.\Gamma_{jt}\right]+\E\left[\tilde{h}(z)\left|\right.\Gamma_{jt}\right]\)`.  

`\begin{aligned}
\tilde{f}\left(\bfx_{jt}\right)&amp;\equiv (1-a)f^{0}\left(\bfx_{jt}\right)+a\phi_{G}\left(\bfx_{jt}\right),\\
\tilde{h}\left(z\right)&amp;\equiv ad+(1-a)h^{0}\left(\frac{z-ad}{1-a}\right).
\end{aligned}`

* For true functions `\(f^{0}, h^{0}\)`, there are infinitely many *wrong* functions `\(\tilde{f}, \tilde{h}\)`, or different "parameters", whose conditional expectations (of functional values) are identical (*observationally equivalent*). 
---
class: inverse
Start from here:
`\begin{equation*}
y_{jt}=f^{0}\left(\bfx_{jt}\right)+h^{0}\left\{\phi_{G}\left(\bfx_{jt-1}\right)+d_{t-1}-f^{0}\left(\bfx_{jt-1}\right)\right\}+\xi_{jt}+\epsilon_{jt}.
\end{equation*}`
Expectation conditional on IVs `\(\Gamma_{jt}=\left(k_{jt}, l_{jt}, \bfx_{jt-1}, d_{t-1}, y_{jt-1}, \cdots\right)\)`: 
`\begin{equation*}
\E\left[y_{jt}|\Gamma_{jt}\right]=\E\left[f^{0}\left(\bfx_{jt}\right)|\Gamma_{jt}\right]+h^{0}\left\{\phi_{G}\left(\bfx_{jt-1}\right)+d_{t-1}-f^{0}\left(\bfx_{jt-1}\right)\right\}.
\end{equation*}`
Note from the definition of `\(\phi_{G}\)`, we have:
`\begin{equation*}
\E\left[y_{jt}|\Gamma_{jt}\right]=\E\left[\phi_{G}\left(\bfx_{jt}\right)+d_{t}|\Gamma_{jt}\right].
\end{equation*}`
Substitute this RHS into LHS of the previous equation, and rearrange:
`\begin{equation}
\E\left[\phi_{G}\left(\bfx_{jt}\right)+d_{t}-f^{0}\left(\bfx_{jt}\right)|\Gamma_{jt}\right]=h^{0}\left\{\phi_{G}\left(\bfx_{jt-1}\right)+d_{t-1}-f^{0}\left(\bfx_{jt-1}\right)\right\}.
\tag{10}
\end{equation}`
---
class: inverse
Define `\(\tilde{f}, \tilde{h}\)` and form systematic part of `\(\tilde{y}_{jt}\)`:
`\begin{aligned}
\tilde{f}\left(\bfx_{jt}\right)&amp;+\tilde{h}\left\{\phi_{G}\left(\bfx_{jt-1}\right)+d_{t-1}-\tilde{f}\left(\bfx_{jt-1}\right)\right\}\\
&amp;=
(1-a)f^{0}\left(\bfx_{jt}\right)+a\phi_{G}\left(\bfx_{jt}\right)+ad+(1-a)h^{0}\left\{\frac{\phi_{G}\left(\bfx_{jt-1}\right)+d-\tilde{f}\left(\bfx_{jt-1}\right)-ad}{1-a}\right\}.
\end{aligned}`
Numerator of square bracket
`\begin{equation*}
\phi_{G}\left(\bfx_{jt-1}\right)+d-(1-a)f^{0}\left(\bfx_{jt-1}\right)-a\phi_{G}\left(\bfx_{jt-1}\right)-ad
=
(1-a)\left\{\phi_{G}\left(\bfx_{jt-1}\right)+d-\tilde{f}\left(\bfx_{jt-1}\right)\right\}.
\end{equation*}`
So
`\begin{equation*}
RHS
=
f^{0}\left(\bfx_{jt}\right)+a\left\{\phi_{G}\left(\bfx_{jt}\right)+d-f^{0}\left(\bfx_{jt}\right)\right\}
+(1-a)h^{0}\left\{\phi_{G}\left(\bfx_{jt-1}\right)+d-f^{0}\left(\bfx_{jt-1}\right)\right\}.
\end{equation*}`
This gives the equivalence result.
`\begin{aligned}
\E&amp;\left[\tilde{f}\left(\bfx_{jt}\right)|\Gamma_{jt}\right]+\tilde{h}\left\{\phi_{G}\left(\bfx_{jt-1}\right)+d_{t-1}-\tilde{f}\left(\bfx_{jt-1}\right)\right\}\\
&amp;\hspace{1em}=
\E\left[f^{0}\left(\bfx_{jt}\right)|\Gamma_{jt}\right]+ah^{0}\left\{\phi_{G}\left(\bfx_{jt}\right)+d-f^{0}\left(\bfx_{jt}\right)\right\}
+(1-a)h^{0}\left\{\phi_{G}\left(\bfx_{jt-1}\right)+d-f^{0}\left(\bfx_{jt-1}\right)\right\},\\
&amp;\hspace{1em}=
\E\left[f^{0}\left(\bfx_{jt}\right)|\Gamma_{jt}\right]+h^{0}\left\{\phi_{G}\left(\bfx_{jt}\right)+d-f^{0}\left(\bfx_{jt}\right)\right\}.
\end{aligned}`
---
class: inverse

Cobb-Douglas + AR(1) `\(\omega_{jt}\)` (dynamic panel) example:

`\begin{aligned}
y_{jt}
&amp;=
\bfalpha'\bfx_{jt}+\omega_{jt}+\epsilon_{jt},\\
\omega_{jt}
&amp;=
\delta_{0}+\delta\omega_{jt-1}+\xi_{jt}.
\end{aligned}`
Substituting `\(\omega_{jt}\)`, this becomes:
`\begin{equation*}
y_{jt}=con+\bfalpha'\bfx_{jt}+\delta\left\{\phi\left(\bfx_{jt-1}\right)+d_{t-1}-\bfalpha'\bfx_{jt-1}\right\}+\xi_{jt}+\epsilon_{jt}.
\end{equation*}`
Expected profit maximisation
`\begin{equation*}
\E[\pi]=P_{t}K^{\alpha_{K}}_{jt}L^{\alpha_{L}}_{jt}M^{\alpha_{M}}_{jt}e^{\omega_{jt}+\epsilon_{jt}}-\rho_{t}M_{jt}.
\end{equation*}`
FOC
`\begin{equation*}
M_{jt}=\frac{\alpha_{M}Y}{\left(\frac{\rho_{t}}{P_{t}}\right)},
\end{equation*}`
so
`\begin{aligned}
m_{jt}
&amp;=
\ln \alpha_{M}+\bfalpha'\bfx_{jt}+\omega_{jt}-\ln\frac{\rho_{t}}{P_{t}}+\E[\epsilon_{jt}],\\
&amp;=
\ln \alpha_{M}+y_{jt}-\epsilon_{jt}-d_{t}.
\end{aligned}`
---
class: inverse
This gives 
`\begin{aligned}
y_{jt}
&amp;=
con+\alpha_{K}k_{jt}+\alpha_{L}l_{jt}+\alpha_{M}\left\{\ln \alpha_{M}+y_{jt}-\epsilon_{jt}-d_{t}\right\}+\delta\{\cdot\}+\xi_{jt}+\epsilon_{jt},\\
&amp;=
\tilde{con}+
\frac{\alpha_{K}}{1-\alpha_{M}}k_{jt}+\frac{\alpha_{L}}{1-\alpha_{M}}l_{jt}-\frac{\alpha_{M}}{1-\alpha_{M}}d_{t}
+\frac{\alpha_{M}}{1-\alpha_{M}}\ln \alpha_{M}\\
&amp;\hspace{2em}+\frac{\delta}{1-\alpha_{M}}\left\{\phi\left(\bfx_{jt-1}\right)+d_{t-1}-\bfalpha'\bfx_{jt}\right\}
+\frac{1}{1-\alpha_{M}}\left(\xi_{jt}+\epsilon_{jt}\right)-\frac{\alpha_{M}}{1-\alpha_{M}}\epsilon_{jt},\\
&amp;=
\tilde{con}+
\frac{\alpha_{K}}{1-\alpha_{M}}k_{jt}+\frac{\alpha_{L}}{1-\alpha_{M}}l_{jt}-\frac{\alpha_{M}}{1-\alpha_{M}}d_{t}+\frac{\delta}{1-\alpha_{M}}d_{t-1}\\
&amp;\hspace{2em}+\frac{\delta}{1-\alpha_{M}}\left\{\phi\left(\bfx_{jt-1}\right)-\bfalpha'\bfx_{jt}\right\}
+\frac{1}{1-\alpha_{M}}\xi_{jt}+\epsilon_{jt}.
\end{aligned}`
Note
`\begin{equation*}
\phi\left(\bfx_{jt}\right)\equiv f\left(\bfx_{jt}\right)+M^{-1}\left(\bfx_{jt}\right)=\bfalpha'\bfx_{jt}-\ln\alpha_{M}+m_{jt}-\bfalpha'\bfx_{jt}=-\ln\alpha_{M}+m_{jt},
\end{equation*}`
we have
`\begin{aligned}
y_{jt}
&amp;=
\tilde{con}+
\frac{\alpha_{K}}{1-\alpha_{M}}k_{jt}+\frac{\alpha_{L}}{1-\alpha_{M}}l_{jt}-\frac{\alpha_{M}}{1-\alpha_{M}}d_{t}+\frac{\delta}{1-\alpha_{M}}d_{t-1}\\
&amp;\hspace{2em}
+\delta\frac{\alpha_{K}}{1-\alpha_{M}}k_{jt-1}
-\delta\frac{\alpha_{L}}{1-\alpha_{M}}l_{jt-1}+\delta m_{jt-1}
+\frac{1}{1-\alpha_{M}}\xi_{jt}+\epsilon_{jt}.
\end{aligned}`
---
class: inverse

Define
`\begin{equation*}
\tilde{\alpha}_{K}=(1-a)\alpha_{K},\quad
\tilde{\alpha}_{L}=(1-a)\alpha_{L},\quad
\tilde{\alpha}_{M}=(1-a)\alpha_{M}+a, \quad \tilde{\delta}=\delta.
\end{equation*}`
Then for any `\(a\in(0,1)\)`
`\begin{equation*}
\frac{\tilde{\alpha}_{K}}{1-\tilde{\alpha}_{M}}=
\frac{\alpha_{K}}{1-\alpha_{M}}, \quad
\frac{\tilde{\alpha}_{L}}{1-\tilde{\alpha}_{M}}=
\frac{\alpha_{L}}{1-\alpha_{M}}.
\end{equation*}`

---
class: inverse, center, middle

# Semi positive result: Nonparametric identification with profit max FOC

---
class: inverse

Price-taking profit maximization gives
`\begin{equation*}
P_{t}\frac{\partial F^{0}\left(\bfx_{jt}\right)}{\partial M_{jt}}e^{\omega_{jt}}\E[e^{\epsilon_{jt}}]=\rho_{t}.
\end{equation*}`
Noting
`\begin{equation*}
\frac{\partial \ln F^{0}\left(\bfx_{jt}\right)}{\partial m_{jt}}=
\frac{\partial \ln F^{0}\left(\bfx_{jt}\right)}{\partial F^{0}}
\frac{\partial F^{0}}{\partial M_{jt}}
\frac{\partial M_{jt}}{\partial m_{jt}}=\frac{1}{F^{0}}F^{0}_{M}M_{jt},
\end{equation*}`
where the last derivative is given by:
`\begin{equation*}
1=\frac{\partial M}{\partial M}=\frac{\partial M}{\partial m}\frac{\partial m}{\partial M}=\frac{\partial M}{\partial m}\frac{1}{M} \quad \Rightarrow \quad \frac{\partial M}{\partial m}=M,
\end{equation*}`
so, 
`\begin{equation*}
F^{0}_{M}=\frac{\partial \ln F^{0}\left(\bfx_{jt}\right)}{\partial m_{jt}}\frac{F^{0}}{M_{jt}}=f^{0}_{m}\left(\bfx_{jt}\right)\frac{F^{0}}{M_{jt}}, \quad f^{0}_{m}\left(\bfx_{jt}\right)\equiv\frac{\partial \ln F^{0}\left(\bfx_{jt}\right)}{\partial m_{jt}}.
\end{equation*}`
Plugging this in gives:
`\begin{aligned}
P_{t}f^{0}_{m}F^{0}\left(\bfx_{jt}\right)e^{\omega_{jt}}\E[e^{\epsilon_{jt}}]&amp;=\rho_{t}M_{jt}.
\end{aligned}`
---
class: inverse
Plugging this in gives:
`\begin{aligned}
P_{t}f^{0}_{m}F^{0}\left(\bfx_{jt}\right)e^{\omega_{jt}}\E[e^{\epsilon_{jt}}]&amp;=\rho_{t}M_{jt},\\
P_{t}f^{0}_{m}\underbrace{F^{0}\left(\bfx_{jt}\right)e^{\omega_{jt}}e^{\epsilon_{jt}}}_{\equiv Y_{jt}}e^{-\epsilon_{jt}}\E[e^{\epsilon_{jt}}]=\rho_{t}M_{jt},\\
f^{0}_{m}e^{-\epsilon_{jt}}\E[e^{\epsilon_{jt}}]=\frac{\rho_{t}M_{jt}}{P_{jt}Y_{jt}}\equiv S_{jt}.
\end{aligned}`
Taking logs and denoting `\(\ln E[e^{\epsilon_{jt}}]=\ln\E\)` gives:
`\begin{equation*}
s_{jt}=\underbrace{\ln f^{0}_{m}+\ln\varepsilon}_{\equiv \ln D^{\epsilon}\left(\bfx_{jt}\right)}-\epsilon_{jt}, \quad D^{\epsilon}\left(\bfx_{jt}\right)=f^{0}_{m}\left(\bfx_{jt}\right)\E[e^{\epsilon_{jt}}].
\end{equation*}`
Equivalently, *share regression* is derived:
`\begin{equation*}
s_{jt}=\ln D^{\epsilon}\left(\bfx_{jt}\right)+u^{\epsilon}_{jt}.
\tag{s}\label{sharereg}
\end{equation*}`

---
class: inverse
### Thereom 2: One can recover `\(\hat{f}_{m}\)` by using the share regression.

Given `\(\omega_{jt}, \bfx_{jt}\in\mathcal I_{jt}\)` we have `\(\E[\epsilon_{jt}|\mathcal I_{jt}]=0\)`, so regressing `\(s_{jt}\)` on a flexible function of `\(\bfx_{jt}\)` identifies `\(f^{0}_{m}\)` as a set of coefficients on the part of `\(m_{jt}\)`. 
`\begin{equation*}
\E\left.\left[s_{jt}\right|\bfx_{jt}\right]=\ln D^{\epsilon}\left(\bfx_{jt}\right).
\end{equation*}`
This identifies `\(D^{\epsilon}\)`. This gives `\(\epsilon_{jt}\)` and `\(\E=\E[e^{\epsilon_{jt}}]\)`:
`\begin{equation*}
\hat{\epsilon}_{jt}=\ln \hat{D}^{\epsilon}-s_{jt}, \quad \hat{\E}=\E\left[e^{\ln \hat{D}^{\epsilon}-s_{jt}}\right].
\end{equation*}`
With the definition of `\(\ln D^{\epsilon}\left(\bfx_{jt}\right)=\ln f_{m}+\ln\E\)`, this gives:
`\begin{aligned}
\ln \hat{f}_{m}
&amp;=\ln \hat{D}^{\epsilon}-\ln\hat{\E},\\
\hat{f}_{m}
&amp;=\frac{\hat{D}^{\epsilon}}{\hat{\E}}.
\end{aligned}`

---
class: inverse
### Thereom 3: Rest of `\(f\)` is recovered up to a constant if `\(\hat{f}_{m}\)` is known.

By the fundamental theorem of calculus:
`\begin{equation}
\int f^{0}_{m}\left(\bfx_{jt}\right)dm_{jt}=f^{0}\left(\bfx_{jt}\right)+\mathcal C(k_{jt}, l_{jt}), \quad \mathrm{or}\quad
f^{0}\left(\bfx_{jt}\right)=\int f^{0}_{m}\left(\bfx_{jt}\right)dm_{jt}-\mathcal C(k_{jt}, l_{jt}).
\tag{f}\label{f0identified}
\end{equation}`
where the constant of integration `\(\mathcal C\)` is allowed to depend on `\(k_{jt}, l_{jt}\)`, or `\(\mathcal C=c_{0}+c_{1}(k_{jt}, l_{jt})\)` without loss of generality. 

### If we can compute `\(c_{1}(k_{jt}, l_{jt})\)`, then we can identify `\(f^{0}\left(\bfx_{jt}\right)\)` up to a constant `\(c_{0}\)`. 

---
class: inverse
Start with the production function in logs:
`\begin{aligned}
\omega_{jt}
&amp;=
y_{jt}-f^{0}-\epsilon_{jt},\\
&amp;=
y_{jt}-\left\{\int f^{0}_{m}\left(\bfx_{jt}\right)dm_{jt}-\mathcal C(k_{jt}, l_{jt})\right\}-\epsilon_{jt}.
\end{aligned}`
Define
`\begin{aligned}
\green{\mathcal Y_{jt}}
&amp;\equiv 
y_{jt}-\int \red{f^{0}_{m}\left(\bfx_{jt}\right)}dm_{jt}-\red{\epsilon_{jt}},\\
&amp;=
\omega_{jt}-\mathcal C(k_{jt}, l_{jt}).
\end{aligned}`
We already .red[have] `\(\red{\hat{\epsilon}_{jt}}\)` and `\(\red{\hat{f}^{0}_{m}}\)`, then we can .green[get] `\(\green{\hat{\mathcal Y}_{jt}}\)`. 

Using first-order Markov on `\(\omega_{jt}\)`
`\begin{aligned}
\omega_{jt}
&amp;=
\mathcal Y_{jt}+\mathcal C(k_{jt}, l_{jt}),\\
\omega_{jt-1}
&amp;=
\mathcal Y_{jt-1}+\mathcal C(k_{jt-1}, l_{jt-1}).
\end{aligned}`
Then
`\begin{aligned}
\mathcal Y_{jt}
&amp;=
h^{0}\left\{\omega_{jt-1}\right\}+\xi_{jt}-\mathcal C(k_{jt}, l_{jt}),\\
&amp;=
h^{0}\left\{\mathcal Y_{jt-1}+\mathcal C(k_{jt-1}, l_{jt-1})\right\}+\xi_{jt}-\mathcal C(k_{jt}, l_{jt}).
\end{aligned}`
---
class: inverse
Denote `\(\Gamma_{y}=(k_{jt}, l_{jt}, k_{jt-1}, l_{jt-1}, \mathcal Y_{jt-1})\)`. Then
`\begin{equation*}
E\left.\left[\mathcal Y_{jt}\right|\Gamma_{y}\right]=-\mathcal C(k_{jt}, l_{jt})+h^{0}\left\{\mathcal Y_{jt-1}+\mathcal C(k_{jt-1}, l_{jt-1})\right\}.
\end{equation*}`

### Partial derivatives `\(c_{1}(k_{jt}, l_{jt})\)` of integration constant `\(\mathcal C\)` are (negative of) coefficients on `\(k_{jt}, l_{jt}\)` conditional on `\(\mathcal Y_{jt-1}, k_{jt-1}, l_{jt-1}\)`.  

* We cannot identify `\(c_{0}\)` part.  
* Using this in \eqref{f0identified} gives `\(\hat{f}^{0}\)` up to a constant.  

### `\(\hat{\omega}_{jt}-c_{0}=\hat{\mathcal Y}_{jt}+\hat{c}_{1}(k_{jt}, l_{jt})\)` is estimable. One can measure productivity differences `\(\hat{\omega}_{jt}-\hat{\omega}_{i't}\)` or `\(\hat{\omega}_{jt}-\hat{\omega}_{it'}\)`. 

---
class: inverse

Cool but *semi* positive results. 

Monopolist profit maximization
`\begin{aligned}
\rho_{t}
&amp;=
\left(\red{P'_{t}F^{0}\left(\bfx_{jt}\right)}+P_{t}\frac{\partial F^{0}\left(\bfx_{jt}\right)}{\partial M_{jt}}\right)e^{\omega_{jt}}\E[e^{\epsilon_{jt}}],\\
&amp;=
\left(\frac{\partial P}{\partial Y_{jt}}\frac{F^{0}\left(\bfx_{jt}\right)}{P_{t}}+f^{0}_{m}\left(\bfx_{jt}\right)\frac{F^{0}}{M_{jt}}\right)P_{t}e^{\omega_{jt}}\E[e^{\epsilon_{jt}}],\\
&amp;=
\left(-\eta^{-1}(\bfx_{jt}, \omega_{jt}, \epsilon_{jt})+f^{0}_{m}\left(\bfx_{jt}\right)\frac{F^{0}e^{\omega_{jt}}\E[e^{\epsilon_{jt}}]}{M_{jt}}\right)P_{t},\\
S_{jt}
&amp;=
-\eta^{-1}(\bfx_{jt}, \omega_{jt}, \epsilon_{jt})\frac{M_{jt}}{Y_{jt}}+f^{0}_{m}\left(\bfx_{jt}\right),\\
&amp;=
-\frac{\eta^{-1}(\red{\bfx_{jt}}, \omega_{jt}, \epsilon_{jt})}{\beta^{M}}+f^{0}_{m}\left(\red{\bfx_{jt}}\right), \quad \beta^{M}\equiv\frac{M_{jt}}{Y_{jt}}.\\
\end{aligned}`

`\(\red{\bfx_{jt}}\)` appears both in `\(\eta\)` and `\(f^{0}_{m}\)` and the two functions cannot be separately nonparametrically identified with the share regression. 

* If we assume an iso-elastic demand function for the output, then elasticity does not depend on `\(\bfx_{jt}\)` and can recover production function parameters. GNR does so in the appendix. 

---
class: inverse, center, middle

# Extensions and empirical exercises

---
class: inverse

* 
[Doraszelski and Jaumandreu (2013)](https://doi.org/10.1093/restud/rdt011) achieves identification of Cobb-Douglas using FOCs. [Doraszelski and Jaumandreu (2018)]( https://doi.org/10.1086/697204) extends it to non-Hicks neutral, CES production.  
* GNR can incoporate firm fixed effects but at the cost of loss of efficiency due to differencing.  

### Using Chile and Columbia data, OLS estimates are overestimated than GNR estimates in more flexible inputs (materials).  
### Less flexible input elasticities are underestimated with OLS. 
### Productivity is more dispersed under GNR estimates. 

---
class: inverse




&lt;a name=bib-AckerbergCavesFrazer2015&gt;&lt;/a&gt;[Ackerberg, D. A., K. Caves, and G.
Frazer](#cite-AckerbergCavesFrazer2015) (2015). "Identification properties of recent production
function estimators". In: _Econometrica_ 83.6, pp. 2411-2451. DOI:
[10.3982/ECTA13408](https://doi.org/10.3982%2FECTA13408).

&lt;a name=bib-BasuFernald1997&gt;&lt;/a&gt;[Basu, S. and J. G. Fernald](#cite-BasuFernald1997) (1997). "Returns to
scale in U.S. production: Estimates and implications". In: _Journal of Political Economy_ 105.2, pp.
249-283. DOI: [10.1086/262073](https://doi.org/10.1086%2F262073).

&lt;a name=bib-Bruno1978&gt;&lt;/a&gt;[Bruno, M.](#cite-Bruno1978) (1978b). "Duality, intermediate inputs and
value-added". In: _Applications of the Theory of Production_. Ed. by M. Fuss and D. McFadden. Vol. 2.
Contributions to Economic Analysis. Elsevier, pp. 3-16.

&lt;a name=bib-DeLoeckerGoldberg2014&gt;&lt;/a&gt;[De Loecker, J. and P. K. Goldberg](#cite-DeLoeckerGoldberg2014)
(2014). "Firm performance in a global market". In: _Annual Review of Economics_ 6.1, pp. 201-227. DOI:
[10.1146/annurev-economics-080113-104741](https://doi.org/10.1146%2Fannurev-economics-080113-104741).

&lt;a name=bib-DeLoeckerSyverson2021&gt;&lt;/a&gt;[De Loecker, J. and C. Syverson](#cite-DeLoeckerSyverson2021)
(2021). "An industrial organization perspective on productivity". In: _Handbook of industrial
organization_. Vol. 4. 1. Elsevier, pp. 141-223.

&lt;a name=bib-Diewert1978&gt;&lt;/a&gt;[Diewert, W. E.](#cite-Diewert1978) (1978). "Hicks' aggregation theorem and
the existence of a real value-added function". In: _Applications of the Theory of Production_. Ed. by
M. Fuss and D. McFadden. Vol. 2. Contributions to Economic Analysis. Elsevier, pp. 17-51.

&lt;a name=bib-DoraszelskiJaumandreu2013&gt;&lt;/a&gt;[Doraszelski, U. and J.
Jaumandreu](#cite-DoraszelskiJaumandreu2013) (2013). "R&amp; D and productivity: Estimating endogenous
productivity". In: _The Review of Economic Studies_ 80.4, pp. 1338-1383. ISSN: 0034-6527. DOI:
[10.1093/restud/rdt011](https://doi.org/10.1093%2Frestud%2Frdt011).

&lt;a name=bib-DoraszelskiJaumandreu2018&gt;&lt;/a&gt;[Doraszelski, U. and J.
Jaumandreu](#cite-DoraszelskiJaumandreu2018) (2018). "Measuring the bias of technological change". In:
_Journal of Political Economy_ 126.3, pp. 1027-1084. DOI:
[10.1086/697204](https://doi.org/10.1086%2F697204).
---
class: inverse


&lt;a name=bib-GNR2017&gt;&lt;/a&gt;[Gandhi, A., S. Navarro, and D. Rivers](#cite-GNR2017) (2017). _How
heterogeneous is productivity? A comparison of gross output and value added_. University of Western
Ontario.

&lt;a name=bib-GNR2020&gt;&lt;/a&gt;[Gandhi, A., S. Navarro, and D. A. Rivers](#cite-GNR2020) (2020). "On the
identification of gross output production functions". In: _Journal of Political Economy_ 128.8, pp.
2973-3016. DOI: [10.1086/707736](https://doi.org/10.1086%2F707736).

&lt;a name=bib-HashemiKirovTraina2022&gt;&lt;/a&gt;[Hashemi, A., I. Kirov, and J.
Traina](#cite-HashemiKirovTraina2022) (2022). "The production approach to markup estimation often
measures input distortions". In: _Economics Letters_ 217, p. 110673. ISSN: 0165-1765. DOI:
[10.1016/j.econlet.2022.110673](https://doi.org/10.1016%2Fj.econlet.2022.110673).

&lt;a name=bib-Rubens2023&gt;&lt;/a&gt;[Rubens, M.](#cite-Rubens2023) (2023). "Market structure, oligopsony power,
and productivity". In: _American Economic Review_ 113.9, pp. 2382-2410. DOI:
[10.1257/aer.20210383](https://doi.org/10.1257%2Faer.20210383).
    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script>var slideshow = remark.create({
"highlightStyle": "github",
"countIncrementalSlides": false,
"ratio": "16:9"
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
// add `data-at-shortcutkeys` attribute to <body> to resolve conflicts with JAWS
// screen reader (see PR #262)
(function(d) {
  let res = {};
  d.querySelectorAll('.remark-help-content table tr').forEach(tr => {
    const t = tr.querySelector('td:nth-child(2)').innerText;
    tr.querySelectorAll('td:first-child .key').forEach(key => {
      const k = key.innerText;
      if (/^[a-z]$/.test(k)) res[k] = t;  // must be a single letter (key)
    });
  });
  d.body.setAttribute('data-at-shortcutkeys', JSON.stringify(res));
})(document);
(function() {
  "use strict"
  // Replace <script> tags in slides area to make them executable
  var scripts = document.querySelectorAll(
    '.remark-slides-area .remark-slide-container script'
  );
  if (!scripts.length) return;
  for (var i = 0; i < scripts.length; i++) {
    var s = document.createElement('script');
    var code = document.createTextNode(scripts[i].textContent);
    s.appendChild(code);
    var scriptAttrs = scripts[i].attributes;
    for (var j = 0; j < scriptAttrs.length; j++) {
      s.setAttribute(scriptAttrs[j].name, scriptAttrs[j].value);
    }
    scripts[i].parentElement.replaceChild(s, scripts[i]);
  }
})();
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
